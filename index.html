<!DOCTYPE html>
<html lang="ru">
<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<link rel="stylesheet" href="css/style.css">
	<title>Lesson_4.1 Произвольная статья</title>
</head>
<body>	
	<header>
		<a href="https://apix-drive.com/ru/blog/news" target="_blank" style="color: green;">Новости</a>
		<a href="https://apix-drive.com/ru/blog/useful" target="_blank" style="font-size: 10px; color: aqua;">Полезное</a>
	</header>

	<div class="preface" style="text-align: justify;">
		<h1>Три способа скрыть сайт от поиска Google</h1>
		<p>Бывают ситуации, когда нужно предотвратить попадание веб-ресурса в поиск Google  либо убрать уже проиндексированный сайт из выдачи. Как это сделать — читайте в нашей статье.</p>
	</div>

	<nav class="list">
		<h2>Содержание</h2>
		<ol>
			<li><a href="#ch1">Как предотвратить попадание сайта в поиск</a></li>
			<li><a href="#ch2">Блокировка сканирования</a></li>
			<li><a href="#ch3">Блокировка индексирования</a></li>
			<li><a href="#ch4">Блокировка с помощью пароля</a></li>
			<li><a href="#ch5">Как удалить уже проиндексированные страницы</a></li>
			<li><a href="#ch6">Заключение</a></li>
		</ol>
	</nav>

	<div class="separator"><p>***</p></div>
	<div class="main-text">
		<div class="chapter-1 text">
			<h2 id="ch1">Как предотвратить попадание сайта в поиск</h2>
			<p>Допустим, ваш сайт еще в процессе разработки и не готов к потоку посетителей из Google. А, может быть, веб-ресурс уже доступен, но вы планируете добавить новый раздел или страницу, но пока не хотите привлекать к ним внимание аудитории. В подобных случаях можно превентивно скрыть весь сайт или его отдельные страницы от поисковой системы. Для этого есть несколько способов.</p>
		</div>

		<div class="chapter-2 text">
			<h2 id="ch2">Блокировка сканирования</h2>
			<p>Google дает возможность запретить поисковому боту сканировать сайт, его разделы или даже отдельные страницы. Это может предотвратить попадание контента в выдачу.</p>
			<p>Нужно лишь добавить несколько команд в файл с названием robots.txt, который должен присутствовать в корневой папке сайта на сервере, и сохранить изменения.</p>
			<p>Команды, которые запретят поисковому боту Google сканировать сайт целиком:</p>
			<p class="center"><span class="link">User-agent: Googlebot Disallow: </span>/</p>
			<p>Команды, которые запретят поисковому боту Google сканировать конкретный раздел сайта (вместо /category нужно указать путь к папке с файлами нужного раздела, исключив из него название сайта):</p>
			<p class="center"><span class="link">User-agent: Googlebot Disallow: /category</span></p>
			<p>Команды, которые запретят поисковому боту Google сканировать конкретную страницу сайта (вместо /category/pagename нужно указать URL страницы, исключив из него название сайта):</p>
			<p class="center"><span class="link">User-agent: Googlebot Disallow: /category/pagename</span></p>
			<p>Но очень важно понимать, что этот способ запрещает роботу только прямое сканирование. Если ссылки на ваш сайт уже есть на внешних ресурах, робот все равно может добавить его в поиск, просто без сканирования.</p>
			<p>Поэтому, Google не рекомендует редактировать robots.txt с целью избежать попадания сайта в поисковую выдачу. Гораздо надежнее использовать способы, перечисленные ниже.</p>
		</div>

		<div class="chapter-3 text">
			<h2 id="ch3">Блокировка индексирования</h2>
			<p>Вы можете не препятствовать сканированию, но при этом запретить саму индексацию страниц — то есть их добавление в выдачу. В результате робот будет проверять содержимое таких страниц, но не станет включать их ссылки в базу поиска.</p>
			<p>Чтобы запретить поисковому роботу Google индексацию страницы, достаточно прописать в ней метатег с директивой noindex. Для этого нужно открыть файл с кодом страницы, найти раздел head и добавить в него строчку <meta name="googlebot" content="noindex">. Если необходимо предотвратить индексацию нескольких страниц, процедуру нужно проделать с каждой из них.</p>
			<div class="img"><img src="img/imgOne.jpg" alt="Пример блокировки индексирования"></div>
			<p>К сожалению, у этого способа тоже есть недостаток. Если по какой-либо причине робот не сможет просканировать страницу, он не увидит директиву noindex и добавит эту страницу в поиск. Такое может произойти, к примеру, если в файле robots.txt будет отключена индексация.</p>
		</div>

		<div class="chapter-4 text">
			<h2 id="ch4">Блокировка с помощью пароля</h2>
			<p>Самый надежный способ предотвратить попадание контента в поиск — поставить пароль на доступ ко всему сайту или же к его файлам, которые хранятся внутри конкретной папки. Эта процедура выполняется по-разному в зависимости от типа используемого сервера, хостинга и движка.</p>
			<p>Обычно пароль можно установить с помощью панели управления сайтом, которую предоставляет хостинг-провайдер. Например, так эта опция выглядит на контрольной панели провайдера Hostinger:</p>
			<p>Если ваш веб-ресурс работает на одном из популярных движков вроде WordPress, скорее всего, инструменты для управления паролем вы также можете найти в настройках используемой платформы или в подключаемых к ней плагинах.</p>
		</div>

		<div class="chapter-5 text">
			<h2 id="ch5">Как удалить уже проиндексированные страницы</h2>
			<p>Что делать, если страницы уже попали в выдачу? В таком случае нужно удалить их из индекса с помощью инструмента Google Search Console. Для этого выполните эти шаги:</p>
			<ol>
				<li>Перейдите по адресу https://search.google.com/search-console/removals.</li>
				<li>Откройте вкладку «Временные удаления».</li>
				<li>Нажмите «Создать запрос».</li>
				<li>Выберите «Временное удаление URL».</li>
				<li>Отправьте запрос на удаление нежелательных страниц с помощью подсказок интерфейса.</li>
				<li>При необходимости повторите эту процедуру с другими страницами.</li>
			</ol>
			<p>Через шесть месяцев после удаления страницы робот может проиндексировать ее снова. Чтобы этого не произошло, удалите страницу с сервера или поставьте пароль на доступ к разделу, в котором она находится.</p>
		</div>

		<div class="chapter-6 text">
			<h2 id="ch6">Заключение</h2>
			<ol>
				<li>Есть несколько способов предотвратить попадание сайта, его раздела или отдельных страниц в поисковую выдачу: 1) заблокировать сканирование с помощью файла robots.txt; 2) заблокировать индексирование с помощью директивы noindex; 3) поставить пароль на доступ ко всему сайту или разделу.
				</li>
				<li>Последний способ — самый надежный. Чтобы данные точно не оказались в выдаче, используйте именно пароль. Инструкцию по его установке на сайт ищите в справочных материалах хостинг-провайдера.
				</li>
				<li>Страницы сайта можно скрыть от Google, даже если они уже попали в индекс. Для этого сначала нужно удалить их из поиска с помощью инструмента Google Search Console. А затем — удалить страницы с сервера или заблокировать к ним доступ через пароль.</li>
			</ol>
		</div>

	</div>
	<div class="separator"><p>***</p></div>

	<footer><a class="end" href="https://apix-drive.com/ru/blog/useful/tri-sposoba-skryt-sajt-ot-poiska-google#remove-from-index-6" target="_blank">Ссылка на саму статью</a></footer>
</body>
</html>